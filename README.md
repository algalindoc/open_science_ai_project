# Open Science AI Project

[![DOI](https://zenodo.org/badge/942804117.svg)](https://doi.org/10.5281/zenodo.14969304)

## ğŸš€ DescripciÃ³n
Este proyecto utiliza **Grobid** y herramientas de anÃ¡lisis de datos en **Python** para extraer informaciÃ³n de documentos cientÃ­ficos en formato PDF. Con Docker, se garantiza una ejecuciÃ³n reproducible y sin complicaciones.

---

## ğŸ“¦ InstalaciÃ³n y ConfiguraciÃ³n

### **1ï¸âƒ£ Requisitos Previos**
- Tener **Docker** y **Docker Compose** instalados.
  - [Descargar Docker](https://www.docker.com/get-started)
  - Abrir la aplicaciÃ³n de docker desktop
- (Opcional) Tener **Python 3.10+** y `pip` instalados si deseas correr el cÃ³digo sin Docker.

### **2ï¸âƒ£ Clonar el Repositorio**
```bash
git clone https://github.com/algalindoc/open_science_ai_project.git
cd open_science_ai_project
```

---

## ğŸ”„ Opciones de EjecuciÃ³n

### **OpciÃ³n 1: Ejecutar con Docker (Recomendada)**
```bash
docker-compose up --build
```
Esto iniciarÃ¡ **Grobid** y el anÃ¡lisis de documentos de forma automatizada. 

âœ… **Los archivos de salida estarÃ¡n en la carpeta `output/`.**

---

### **OpciÃ³n 2: Ejecutar sin Docker**
Si prefieres no usar Docker, sigue estos pasos:

1ï¸âƒ£ **Crear un entorno virtual**
```bash
python -m venv env
source env/bin/activate  # En Linux/Mac
env\Scripts\activate  # En Windows
```

2ï¸âƒ£ **Instalar dependencias**
```bash
pip install -r requirements.txt
```

3ï¸âƒ£ **Ejecutar el anÃ¡lisis**
```bash
python scripts/main.py
```
âœ… **Los archivos procesados se guardarÃ¡n en `output/`**.

4ï¸âƒ£ **Desactivar el entorno virtual (opcional)**
```bash
deactivate
```

---

## ğŸ› ï¸ Uso del Proyecto

### **1ï¸âƒ£ Agregar PDFs para Analizar**
Coloca los archivos **.pdf** en la carpeta `papers/`.

### **2ï¸âƒ£ Revisar Resultados**
Los resultados se guardan en `output/`:
- `results.csv` ğŸ“ â†’ Tabla con tÃ­tulos, resÃºmenes, figuras y enlaces extraÃ­dos.
- `figures_per_article.png` ğŸ“Š â†’ GrÃ¡fico de nÃºmero de figuras por artÃ­culo.
- `wordcloud.png` â˜ï¸ â†’ Nube de palabras basada en los resÃºmenes.
- `links_found.txt` ğŸ”— â†’ Lista de enlaces extraÃ­dos de los documentos.

---

## âœ… Ejecutar Pruebas Unitarias
Si deseas verificar que todo funcione correctamente:
```bash
docker exec -it open_science_analysis pytest
```
Esto ejecutarÃ¡ las pruebas en `tests/` para validar la extracciÃ³n de datos.

---

## ğŸ“Œ Estructura del Proyecto
```
open_science_ai_project/
â”‚â”€â”€ papers/              # Carpeta donde colocar los PDFs para analizar
â”‚â”€â”€ output/              # Carpeta donde se guardan los resultados
â”‚â”€â”€ scripts/             # CÃ³digo fuente
â”‚   â”œâ”€ main.py          # Script principal
â”‚   â”œâ”€ process_papers.py # Procesa PDFs con Grobid
â”‚   â””â”€ extract_data.py  # Extrae y analiza datos de los documentos
â”‚â”€â”€ tests/               # Pruebas unitarias
â”‚â”€â”€ Dockerfile           # ConfiguraciÃ³n de Docker
â”‚â”€â”€ docker-compose.yml   # ConfiguraciÃ³n de Docker Compose
â”‚â”€â”€ requirements.txt     # Dependencias del proyecto
â”‚â”€â”€ codemeta.json        # Archivo de metadatos JSON-LD
â”‚â”€â”€ README.md            # DocumentaciÃ³n principal
```

---

## ğŸ“ Licencia
Este proyecto estÃ¡ bajo la licencia MIT.  
Puedes leer mÃ¡s en el archivo [`LICENSE`](LICENSE).


