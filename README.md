# Open Science AI Project

## ğŸš€ DescripciÃ³n
Este proyecto utiliza **Grobid** y herramientas de anÃ¡lisis de datos en **Python** para extraer informaciÃ³n de documentos cientÃ­ficos en formato PDF. Con Docker, se garantiza una ejecuciÃ³n reproducible y sin complicaciones.

---

## ğŸ“¦ InstalaciÃ³n y ConfiguraciÃ³n

### **1ï¸âƒ£ Requisitos Previos**
- Tener **Docker** y **Docker Compose** instalados.
  - [Descargar Docker](https://www.docker.com/get-started)
- (Opcional) Tener **Python 3.10+** y `pip` instalados si deseas correr el cÃ³digo sin Docker.

### **2ï¸âƒ£ Clonar el Repositorio**
```bash
git clone https://github.com/tu-usuario/open_science_ai_project.git
cd open_science_ai_project
```

### **3ï¸âƒ£ Ejecutar el Proyecto con Docker**
Para ejecutar el proyecto con **Docker Compose**:
```bash
docker-compose up --build
```
Esto iniciarÃ¡ **Grobid** y el anÃ¡lisis de documentos.

âœ… **Los archivos de salida estarÃ¡n en la carpeta `output/`**.


---

## ğŸ› ï¸ Uso del Proyecto

### **1ï¸âƒ£ Agregar PDFs para Analizar**
Coloca los archivos **.pdf** en la carpeta `papers/`.

### **2ï¸âƒ£ Ejecutar el AnÃ¡lisis Manualmente**
Si ya tienes Docker en ejecuciÃ³n pero quieres ejecutar el script manualmente dentro del contenedor:
```bash
docker exec -it open_science_analysis python scripts/main.py
```

### **3ï¸âƒ£ Revisar Resultados**
Los resultados se guardan en `output/`:
- `results.csv` ğŸ“„ â†’ Tabla con tÃ­tulos, resÃºmenes, figuras y enlaces extraÃ­dos.
- `figures_per_article.png` ğŸ“Š â†’ GrÃ¡fico de nÃºmero de figuras por artÃ­culo.
- `wordcloud.png` â˜ï¸ â†’ Nube de palabras basada en los resÃºmenes.
- `links_found.txt` ğŸ”— â†’ Lista de enlaces extraÃ­dos de los documentos.

---

## âœ… Ejecutar Pruebas Unitarias
Si deseas verificar que todo funcione correctamente:
```bash
docker exec -it open_science_analysis pytest
```
Esto ejecutarÃ¡ las pruebas en `tests/` para validar la extracciÃ³n de datos.

---

## ğŸ“Œ Estructura del Proyecto
```
open_science_ai_project/
â”‚â”€â”€ papers/              # Carpeta donde colocar los PDFs para analizar
â”‚â”€â”€ output/              # Carpeta donde se guardan los resultados
â”‚â”€â”€ scripts/             # CÃ³digo fuente
â”‚   â”œâ”€â”€ main.py          # Script principal
â”‚   â”œâ”€â”€ process_papers.py # Procesa PDFs con Grobid
â”‚   â”œâ”€â”€ extract_data.py  # Extrae y analiza datos de los documentos
â”‚â”€â”€ tests/               # Pruebas unitarias
â”‚â”€â”€ Dockerfile           # ConfiguraciÃ³n de Docker
â”‚â”€â”€ docker-compose.yml   # ConfiguraciÃ³n de Docker Compose
â”‚â”€â”€ requirements.txt     # Dependencias del proyecto
â”‚â”€â”€ README.md            # DocumentaciÃ³n principal
```

---

## ğŸ’¡ Futuras Mejoras
ğŸ“Œ **Agregar soporte para anÃ¡lisis de grÃ¡ficos y tablas.**
ğŸ“Œ **Optimizar el preprocesamiento de texto con NLP.**
ğŸ“Œ **Integrar visualizaciÃ³n interactiva de los resultados.**

---

## ğŸ“„ Licencia
Este proyecto estÃ¡ bajo la licencia MIT. Â¡SiÃ©ntete libre de contribuir! ğŸ˜Š

